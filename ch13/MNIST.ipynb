{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-07-03T01:20:48.295167Z",
     "start_time": "2023-07-03T01:20:48.258703Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "image_path = './'\n",
    "transforms = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "mnist_train_dataset = torchvision.datasets.MNIST(\n",
    "    root = image_path,\n",
    "    train=True,\n",
    "    transform=transforms,\n",
    "    download=True\n",
    ")\n",
    "\n",
    "mnist_test_dataset = torchvision.datasets.MNIST(\n",
    "    root = image_path,\n",
    "    train=False,\n",
    "    transform=transforms,\n",
    "    download=False\n",
    ")\n",
    "\n",
    "batch_size = 64\n",
    "torch.manual_seed(1)\n",
    "\n",
    "train_dl = DataLoader(mnist_train_dataset, batch_size=batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "Sequential(\n  (0): Flatten(start_dim=1, end_dim=-1)\n  (1): Linear(in_features=784, out_features=32, bias=True)\n  (2): ReLU()\n  (3): Linear(in_features=32, out_features=16, bias=True)\n  (4): ReLU()\n  (5): Linear(in_features=16, out_features=10, bias=True)\n)"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_units = [32, 16]\n",
    "image_size = mnist_train_dataset[0][0].shape\n",
    "input_size = image_size[0] * image_size[1] * image_size[2]\n",
    "\n",
    "all_layers = [nn.Flatten()]\n",
    "for hidden_unit in hidden_units:\n",
    "    layer = nn.Linear(input_size, hidden_unit)\n",
    "    all_layers.append(layer)\n",
    "    all_layers.append(nn.ReLU())\n",
    "    input_size = hidden_unit\n",
    "\n",
    "all_layers.append(nn.Linear(hidden_units[-1], 10))\n",
    "\n",
    "model = nn.Sequential(*all_layers)\n",
    "model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-03T01:25:12.786331Z",
     "start_time": "2023-07-03T01:25:12.776275Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[21], line 11\u001B[0m\n\u001B[1;32m      9\u001B[0m pred \u001B[38;5;241m=\u001B[39m model(x_batch)\n\u001B[1;32m     10\u001B[0m loss \u001B[38;5;241m=\u001B[39m loss_fn(pred, y_batch)\n\u001B[0;32m---> 11\u001B[0m \u001B[43mloss\u001B[49m\u001B[38;5;241m.\u001B[39mbackward()\n\u001B[1;32m     12\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mstep()\n\u001B[1;32m     13\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n",
      "Cell \u001B[0;32mIn[21], line 11\u001B[0m\n\u001B[1;32m      9\u001B[0m pred \u001B[38;5;241m=\u001B[39m model(x_batch)\n\u001B[1;32m     10\u001B[0m loss \u001B[38;5;241m=\u001B[39m loss_fn(pred, y_batch)\n\u001B[0;32m---> 11\u001B[0m \u001B[43mloss\u001B[49m\u001B[38;5;241m.\u001B[39mbackward()\n\u001B[1;32m     12\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mstep()\n\u001B[1;32m     13\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n",
      "File \u001B[0;32m_pydevd_bundle/pydevd_cython_darwin_310_64.pyx:1179\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_darwin_310_64.SafeCallWrapper.__call__\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m_pydevd_bundle/pydevd_cython_darwin_310_64.pyx:620\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_darwin_310_64.PyDBFrame.trace_dispatch\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m_pydevd_bundle/pydevd_cython_darwin_310_64.pyx:1095\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_darwin_310_64.PyDBFrame.trace_dispatch\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m_pydevd_bundle/pydevd_cython_darwin_310_64.pyx:1053\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_darwin_310_64.PyDBFrame.trace_dispatch\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m/Applications/DataSpell.app/Contents/plugins/python-ce/helpers-pro/jupyter_debug/pydev_jupyter_plugin.py:169\u001B[0m, in \u001B[0;36mstop\u001B[0;34m(plugin, pydb, frame, event, args, stop_info, arg, step_cmd)\u001B[0m\n\u001B[1;32m    167\u001B[0m     frame \u001B[38;5;241m=\u001B[39m suspend_jupyter(main_debugger, thread, frame, step_cmd)\n\u001B[1;32m    168\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m frame:\n\u001B[0;32m--> 169\u001B[0m         \u001B[43mmain_debugger\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdo_wait_suspend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mthread\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mframe\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mevent\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43marg\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    170\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m    171\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "File \u001B[0;32m/Applications/DataSpell.app/Contents/plugins/python-ce/helpers/pydev/pydevd.py:1160\u001B[0m, in \u001B[0;36mPyDB.do_wait_suspend\u001B[0;34m(self, thread, frame, event, arg, send_suspend_message, is_unhandled_exception)\u001B[0m\n\u001B[1;32m   1157\u001B[0m         from_this_thread\u001B[38;5;241m.\u001B[39mappend(frame_id)\n\u001B[1;32m   1159\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_threads_suspended_single_notification\u001B[38;5;241m.\u001B[39mnotify_thread_suspended(thread_id, stop_reason):\n\u001B[0;32m-> 1160\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_do_wait_suspend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mthread\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mframe\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mevent\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43marg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msuspend_type\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfrom_this_thread\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Applications/DataSpell.app/Contents/plugins/python-ce/helpers/pydev/pydevd.py:1175\u001B[0m, in \u001B[0;36mPyDB._do_wait_suspend\u001B[0;34m(self, thread, frame, event, arg, suspend_type, from_this_thread)\u001B[0m\n\u001B[1;32m   1172\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_mpl_hook()\n\u001B[1;32m   1174\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprocess_internal_commands()\n\u001B[0;32m-> 1175\u001B[0m         \u001B[43mtime\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msleep\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0.01\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1177\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcancel_async_evaluation(get_current_thread_id(thread), \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mid\u001B[39m(frame)))\n\u001B[1;32m   1179\u001B[0m \u001B[38;5;66;03m# process any stepping instructions\u001B[39;00m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "torch.manual_seed(1)\n",
    "num_epochs = 20\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    accuracy_hist_train = 0\n",
    "    for x_batch, y_batch in train_dl:\n",
    "        pred = model(x_batch)\n",
    "        loss = loss_fn(pred, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        is_correct = (\n",
    "            torch.argmax(pred, dim=1) == y_batch\n",
    "        ).float()\n",
    "        accuracy_hist_train += is_correct.sum()\n",
    "    accuracy_hist_train /= len(train_dl.dataset)\n",
    "    print(f'Epoch {epoch}  Accuracy {accuracy_hist_train:.4f}')\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.9669\n"
     ]
    }
   ],
   "source": [
    "# evaluation\n",
    "pred = model(mnist_test_dataset.data / 255.)\n",
    "is_correct = (\n",
    "    torch.argmax(pred, dim=1) == mnist_test_dataset.targets\n",
    ").float()\n",
    "\n",
    "print(f'Test accuracy: {is_correct.mean():.4f}')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-03T01:43:37.955532Z",
     "start_time": "2023-07-03T01:43:37.937183Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n        [  0,   0,   0,   0,   0,   0,  84, 185, 159, 151,  60,  36,   0,   0,\n           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n        [  0,   0,   0,   0,   0,   0, 222, 254, 254, 254, 254, 241, 198, 198,\n         198, 198, 198, 198, 198, 198, 170,  52,   0,   0,   0,   0,   0,   0],\n        [  0,   0,   0,   0,   0,   0,  67, 114,  72, 114, 163, 227, 254, 225,\n         254, 254, 254, 250, 229, 254, 254, 140,   0,   0,   0,   0,   0,   0],\n        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  17,  66,  14,\n          67,  67,  67,  59,  21, 236, 254, 106,   0,   0,   0,   0,   0,   0],\n        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n           0,   0,   0,   0,  83, 253, 209,  18,   0,   0,   0,   0,   0,   0],\n        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n           0,   0,   0,  22, 233, 255,  83,   0,   0,   0,   0,   0,   0,   0],\n        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n           0,   0,   0, 129, 254, 238,  44,   0,   0,   0,   0,   0,   0,   0],\n        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n           0,   0,  59, 249, 254,  62,   0,   0,   0,   0,   0,   0,   0,   0],\n        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n           0,   0, 133, 254, 187,   5,   0,   0,   0,   0,   0,   0,   0,   0],\n        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n           0,   9, 205, 248,  58,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n           0, 126, 254, 182,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          75, 251, 240,  57,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  19,\n         221, 254, 166,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3, 203,\n         254, 219,  35,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  38, 254,\n         254,  77,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  31, 224, 254,\n         115,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 133, 254, 254,\n          52,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  61, 242, 254, 254,\n          52,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 121, 254, 254, 219,\n          40,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 121, 254, 207,  18,\n           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]],\n       dtype=torch.uint8)"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_test_dataset.data[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-03T01:46:31.477182Z",
     "start_time": "2023-07-03T01:46:31.466767Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,  18,\n          18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,   0,   0],\n        [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170, 253,\n         253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,   0,   0],\n        [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253, 253,\n         253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,   0,   0],\n        [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253, 253,\n         198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n        [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253, 205,\n          11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n        [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,  90,\n           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253, 190,\n           2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190, 253,\n          70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35, 241,\n         225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  81,\n         240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,   0,   0],\n        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n           0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,   0,   0],\n        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n           0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,   0,   0],\n        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,   0,   0],\n        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39, 148,\n         229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,   0,   0],\n        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221, 253,\n         253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n        [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253, 253,\n         253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n        [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253, 195,\n          80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n        [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,  11,\n           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n        [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,   0,\n           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]],\n       dtype=torch.uint8)"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_train_dataset.data[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-03T01:46:40.916199Z",
     "start_time": "2023-07-03T01:46:40.911445Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
