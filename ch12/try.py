import torch
from torch.utils.data import DataLoader

t = torch.arange(6, dtype=torch.float32)
data_loader = DataLoader(t)

for item in data_loader:
    print(item)

data_loader = DataLoader(t, batch_size=5, drop_last=False)
for i, batch in enumerate(data_loader, 1):
    print(f'batch {i}:', batch)
